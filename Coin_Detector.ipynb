{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coin Accounter System "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import isfile as exist\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import itemfreq\n",
    "from pylab import arange, array\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import warnings\n",
    "import pickle\n",
    "import glob\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para facilitar a visualização das imagens\n",
    "def showit(img, openCV=0, text='t'):\n",
    "    \n",
    "    if(openCV):\n",
    "        cv.imshow(text, img)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()\n",
    "    \n",
    "    else:  \n",
    "        # Para imagens preto e branco\n",
    "        if(len(img.shape) < 3):\n",
    "            plt.gray()\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.imshow(img[:,:,::-1])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img, cols=800):    \n",
    "    d = cols / img.shape[1]\n",
    "    dim = (cols, int(img.shape[0] * d))\n",
    "    img = cv.resize(img, dim, interpolation=cv.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "def convolution(img, a, b):\n",
    "    kernel = np.array([[a,a,a],[a,b,a],[a,a,a]])\n",
    "    img = cv.filter2D(img,-1,kernel)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Coin ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleCount = 0\n",
    "\n",
    "# Função que retorna a mascara das moedas na imagem\n",
    "def getMask(img):\n",
    "    \n",
    "    img = cv.bitwise_not(img, img)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    limiar, img = cv.threshold(img, 30, 255, cv.THRESH_BINARY) # limiar de otsu inclui as sombras\n",
    "    \n",
    "    stt = cv.getStructuringElement(cv.MORPH_ELLIPSE, (11,11))\n",
    "    mask = cv.morphologyEx(img, cv.MORPH_CLOSE, stt, iterations=7)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# Função que encontrar a moeda na imagem e retorna o menor quadrado envolvente com a moeda\n",
    "def findSingleCoin(imgCol):\n",
    "    \n",
    "    # Reduz tamanho da imagem\n",
    "    imgCol = resize(imgCol, 800)\n",
    "    \n",
    "    # Eliminar sombras da imagem\n",
    "    imgCol = convolution(imgCol, -1/4, 4)\n",
    "        \n",
    "    # Encontro a Região de Interesse\n",
    "    imgBin = getMask(imgCol)\n",
    "\n",
    "    # Selecionando região de interesse na imagem colorida com a máscara encontrada\n",
    "    imgCol = cv.bitwise_and(imgCol, imgCol, mask=imgBin)\n",
    "    \n",
    "    # Achar contornos das moedas\n",
    "    moedas, hierarquia = cv.findContours(imgBin, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "    # Para cada moeda encontrada\n",
    "    for moeda in moedas:\n",
    "        \n",
    "        # Não contabilizar regiões de falhas\n",
    "        area = cv.contourArea(moeda)\n",
    "        if(area < 5000.0):            \n",
    "            continue\n",
    "            \n",
    "        # Encontre o menor retângulo envolvente\n",
    "        x, y, w, h = cv.boundingRect(moeda)\n",
    "\n",
    "        # Nova imagem com o menor retângulo envolvente da moeda\n",
    "        imgCoinRoi = imgCol[y:y+h, x:x+w]\n",
    "        \n",
    "        # Writing results in results folder\n",
    "        global singleCount\n",
    "        singleCount += 1\n",
    "        cv.imwrite(\"singleCoins/coin{}.png\".format(singleCount), imgCoinRoi)\n",
    "        \n",
    "        return imgCoinRoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractions Functions Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saturationHistogram(img):\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2HSV)    \n",
    "    hist = cv.calcHist([img],[0],None,[256],[0,256])\n",
    "    hist = cv.normalize(hist, None)\n",
    "    \n",
    "    soma=0\n",
    "    for i in hist.flatten():\n",
    "        soma += i\n",
    "    \n",
    "    return soma/256\n",
    "\n",
    "def coloredHistogram(img):\n",
    "    \n",
    "    histBlue = cv.calcHist([img[:,:,0]],[0],None,[256],[0,256])\n",
    "    histBlue = cv.normalize(histBlue, None)\n",
    "    \n",
    "    histGreen = cv.calcHist([img[:,:,1]],[0],None,[256],[0,256])\n",
    "    histGreen = cv.normalize(histGreen, None)\n",
    "    \n",
    "    histRed = cv.calcHist([img[:,:,2]],[0],None,[256],[0,256])\n",
    "    histRed = cv.normalize(histRed, None)\n",
    "    \n",
    "    for i in range(len(histBlue)):\n",
    "        histBlue[i] = min(histBlue[i], histGreen[i], histRed[i])\n",
    "        \n",
    "    soma=0\n",
    "    for i in histBlue.flatten():\n",
    "        soma += i\n",
    "    \n",
    "    return soma/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(imag, roiDefined=False):\n",
    "    \n",
    "    if(not roiDefined):\n",
    "        imag = findSingleCoin(imag)\n",
    "        \n",
    "    meanColor = coloredHistogram(imag)\n",
    "    \n",
    "    meanSaturation = saturationHistogram(imag)\n",
    "    \n",
    "    # LBP Invariant\n",
    "    img = cv.cvtColor(imag.copy(), cv.COLOR_BGR2GRAY)\n",
    "    lbp = local_binary_pattern(img,8,2,method='uniform')\n",
    "    lbp_hist = itemfreq(lbp).flatten()\n",
    "    lbp_hist = [float(i)/max(lbp_hist) for i in lbp_hist]\n",
    "    \n",
    "    return np.append(np.append(lbp_hist, meanColor), meanSaturation)\n",
    "        \n",
    "def extractionFromFile(file):\n",
    "    img = cv.imread(file)\n",
    "    return extraction(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 imagens falharam na extração de características\n",
      "--- 77.92105460166931 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([\"Cinco\", \"Dez\", \"Vinte Cinco\", \"Cinquenta\", \"Real\"])\n",
    "\n",
    "if(exist(\"coin_features\") and exist(\"coin_features_answer\")):\n",
    "    \n",
    "    with open('coin_features', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    with open('coin_features_answer', 'rb') as f:\n",
    "        answrData = pickle.load(f)\n",
    "    \n",
    "    with open('ArffData', 'rb') as f:\n",
    "        arffData = pickle.load(f)\n",
    "        \n",
    "else:\n",
    "    \n",
    "    # Defina onde está a pasta do dataset da moeda\n",
    "    coin_directory = \"moedas/\"\n",
    "\n",
    "    # Lista com o nome das imagens nesse diretório\n",
    "    sample_images_5_back = glob.glob(coin_directory + \"5/back/*\")\n",
    "    sample_images_5_front = glob.glob(coin_directory + \"5/front/*\")\n",
    "\n",
    "    sample_images_10_back = glob.glob(coin_directory  + \"10/back/*\")\n",
    "    sample_images_10_front = glob.glob(coin_directory + \"10/front/*\")\n",
    "\n",
    "    sample_images_25_back = glob.glob(coin_directory  + \"25/back/*\")\n",
    "    sample_images_25_front = glob.glob(coin_directory + \"25/front/*\")\n",
    "\n",
    "    sample_images_50_back = glob.glob(coin_directory  + \"50/back/*\")\n",
    "    sample_images_50_front = glob.glob(coin_directory + \"50/front/*\")\n",
    "\n",
    "    sample_images_100_back = glob.glob(coin_directory  + \"100/back/*\")\n",
    "    sample_images_100_front = glob.glob(coin_directory + \"100/front/*\")\n",
    "\n",
    "    # Lista com as características das imagens e suas respectivas classificações\n",
    "    data = []\n",
    "    answrData = []\n",
    "    arffData = []\n",
    "    \n",
    "    qntFailure = 0\n",
    "    FailureList = []\n",
    "    \n",
    "    # Extraindo características das moedas sozinhas\n",
    "    for i in sample_images_5_front:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(le.transform([\"Cinco\"]))\n",
    "            arffData.append((features, str(le.transform([\"Cinco\"]))))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "\n",
    "    for i in sample_images_5_back:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(le.transform([\"Cinco\"]))\n",
    "            arffData.append((features, str(le.transform([\"Cinco\"]))))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_10_front:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(le.transform([\"Dez\"]))\n",
    "            arffData.append((features, str(le.transform([\"Dez\"]))))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_10_back:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(le.transform([\"Dez\"]))\n",
    "            arffData.append((features, str(le.transform([\"Dez\"]))))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_25_front:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(le.transform([\"Vinte Cinco\"]))\n",
    "            arffData.append((features, str(le.transform([\"Vinte Cinco\"]))))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_25_back:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(le.transform([\"Vinte Cinco\"]))\n",
    "            arffData.append((features, str(le.transform([\"Vinte Cinco\"]))))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_50_front:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(le.transform([\"Cinquenta\"]))\n",
    "            arffData.append((features, str(le.transform([\"Cinquenta\"]))))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_50_back:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(le.transform([\"Cinquenta\"]))\n",
    "            arffData.append((features, str(le.transform([\"Cinquenta\"]))))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_100_front:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(le.transform([\"Real\"]))\n",
    "            arffData.append((features, str(le.transform([\"Real\"])))) \n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_100_back:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(le.transform([\"Real\"]))\n",
    "            arffData.append((features, str(le.transform([\"Real\"]))))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "    \n",
    "    c = 0  \n",
    "    for i in FailureList:\n",
    "        img = cv.imread(i)\n",
    "        c += 1\n",
    "        cv.imwrite(\"fail_img/coin{}.png\".format(c), img)\n",
    "    \n",
    "    print(qntFailure, \"imagens falharam na extração de características\")\n",
    "\n",
    "    if(not qntFailure):\n",
    "        # Save the results\n",
    "        with open('coin_features', 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "        with open('coin_features_answer', 'wb') as f:\n",
    "            pickle.dump(answrData, f)\n",
    "\n",
    "        with open('ArffData', 'wb') as f:\n",
    "            pickle.dump(arffData, f)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75% para treino, 25% da medir a accuracia\n",
    "data_train, data_test, asw_train, asw_test = train_test_split(\n",
    "    data, answrData, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier mean accuracy:  85 %\n"
     ]
    }
   ],
   "source": [
    "trReg = DecisionTreeRegressor().fit(data_train,asw_train)\n",
    "# t.predict(test)\n",
    "\n",
    "score = int(trReg.score(data_test, asw_test) * 100)\n",
    "print(\"Classifier mean accuracy: \", score, \"%\")\n",
    "trReg = DecisionTreeRegressor().fit(data,answrData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rogeriojunior/gpam/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier mean accuracy:  36 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rogeriojunior/gpam/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.7167706489562988 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "mlp = MLPClassifier(solver=\"lbfgs\").fit(data_train,asw_train)\n",
    "\n",
    "score = int(mlp.score(data_test, asw_test) * 100)\n",
    "print(\"Classifier mean accuracy: \", score, \"%\")\n",
    "mlp = MLPClassifier(solver=\"lbfgs\").fit(data,answrData)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier mean accuracy:  92 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rogeriojunior/gpam/lib/python3.5/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/rogeriojunior/gpam/lib/python3.5/site-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100).fit(data_train,asw_train)\n",
    "# clf.predict(test)\n",
    "\n",
    "score = int(clf.score(data_test, asw_test) * 100)\n",
    "print(\"Classifier mean accuracy: \", score, \"%\")\n",
    "clf = RandomForestClassifier(n_estimators=50, bootstrap = True, max_features = 'sqrt').fit(data_train,asw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier mean accuracy:  91 %\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier().fit(data_train,asw_train)\n",
    "# tree.predict()\n",
    "\n",
    "score = int(tree.score(data_test, asw_test) * 100)\n",
    "print(\"Classifier mean accuracy: \", score, \"%\")\n",
    "tree = DecisionTreeClassifier().fit(data_train,asw_train).fit(data,answrData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecione qual classificador será usado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = trReg  # DecisionTreeRegressor\n",
    "# classifier = tree   # DecisionTreeClassifier\n",
    "# classifier = mlp    # MLPClassifier\n",
    "classifier = clf      # RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predictCoin(roi):\n",
    "        \n",
    "    hist = extraction(roi, True)\n",
    "    s = classifier.predict([hist])\n",
    "    \n",
    "    # Lista com as probabilidade de cada moeda\n",
    "    a = classifier.predict_proba([hist]).tolist()\n",
    "        \n",
    "    return le.inverse_transform(s.astype(int))[0], max(a[0])\n",
    "\n",
    "def getMask(img, RoiDefined=False):\n",
    "\n",
    "    img = cv.bitwise_not(img, img)\n",
    "    \n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    limiar, img = cv.threshold(img, 0, 255, cv.THRESH_BINARY) # limiar de otsu inclui as sombras\n",
    "        \n",
    "    if(RoiDefined):\n",
    "        size=2\n",
    "        times=15\n",
    "    else:\n",
    "        size=5\n",
    "        times=20\n",
    "    \n",
    "    stt = cv.getStructuringElement(cv.MORPH_ELLIPSE, (size,size))\n",
    "    mask = cv.morphologyEx(img, cv.MORPH_CLOSE, stt, iterations=times)\n",
    "        \n",
    "#     showit(mask,1)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def findMultiplesCoin(imgCol):\n",
    "    \n",
    "    imgBin = getMask(imgCol)\n",
    "    imgCol = cv.bitwise_and(imgCol, imgCol, mask=imgBin)\n",
    "        \n",
    "    img = cv.cvtColor(imgCol, cv.COLOR_BGR2GRAY)\n",
    "    img = cv.bilateralFilter(img, 5, 90, 90)\n",
    "        \n",
    "#     showit(img, 1)\n",
    "    \n",
    "    circles = cv.HoughCircles(img,method=cv.HOUGH_GRADIENT,dp=1,minDist=100,\n",
    "                               param1=50,param2=50,minRadius=40,maxRadius=80)\n",
    "    \n",
    "    return circles\n",
    "\n",
    "# Imagem que será analisada\n",
    "ct = 0\n",
    "def coin_detector(img, name):\n",
    "    img = resize(img, 800)\n",
    "    img = convolution(img, -1/4, 4)\n",
    "    \n",
    "    output = img.copy()\n",
    "    \n",
    "#     showit(img, 1)\n",
    "\n",
    "    circles = findMultiplesCoin(img)\n",
    "\n",
    "    form = img.copy()\n",
    "    \n",
    "    listCoins = []\n",
    "\n",
    "    count = 0\n",
    "    if circles is not None:\n",
    "        \n",
    "        # coordinates and radii\n",
    "        circles = np.round(circles[0,:]).astype(int)\n",
    "\n",
    "        for (x, y, d) in circles:\n",
    "\n",
    "            count += 1 # Qnt de moedas\n",
    "#             d+=7 # Increase radius\n",
    "\n",
    "            form[:,:,:]=0\n",
    "\n",
    "            cv.circle(form,(x,y), d, (255,255,255), -1)\n",
    "            img2gray = cv.cvtColor(form, cv.COLOR_BGR2GRAY)\n",
    "            ret, imgBin = cv.threshold(img2gray, 0, 255, cv.THRESH_BINARY)\n",
    "\n",
    "#             showit(form,1)\n",
    "\n",
    "            roi = cv.bitwise_and(img, img, mask=imgBin)\n",
    "            roi = roi[y-d:y+d, x-d:x+d]\n",
    "        \n",
    "            listCoins.append(roi)\n",
    "\n",
    "#             showit(roi[::2,::2],1)\n",
    "\n",
    "            coin, chance = predictCoin(roi)\n",
    "\n",
    "            chance = str(int(chance*100)) + \" %\"\n",
    "\n",
    "            cv.circle(output, (x,y), d, (0, 255, 0), 2)\n",
    "            cv.putText(output, coin, (x - 40, y), cv.FONT_HERSHEY_PLAIN,\n",
    "                       1.5, (0, 255, 0), thickness=2, lineType=cv.LINE_AA)\n",
    "\n",
    "            cv.putText(output, chance, (x - 20, y+30), cv.FONT_HERSHEY_PLAIN,\n",
    "                       1.5, (0, 255, 0), thickness=2, lineType=cv.LINE_AA)\n",
    "    \n",
    "    showit(output, 1, name)\n",
    "    global ct\n",
    "    ct += 1\n",
    "    cv.imwrite(\"final_result/coin{}.png\".format(ct), output)\n",
    "    \n",
    "    return listCoins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = glob.glob('moedas/juntas/*')\n",
    "\n",
    "count = 0\n",
    "\n",
    "for file in sample:\n",
    "    img = cv.imread(file)\n",
    "    \n",
    "    listCoins = coin_detector(img, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivo ARFF para testar no Weka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile as exist\n",
    "\n",
    "def gravar_arquivo_arff(base_teste, classes):\n",
    "    tam = len(base_teste[0])\n",
    "    file = open('data.arff','w') \n",
    " \n",
    "    file.write('@relation teste\\n') \n",
    "    for i in range(tam):\n",
    "        file.write('@attribute '+ str(i) +' NUMERIC\\n') \n",
    "    \n",
    "    file.write('@attribute classes {')\n",
    "    \n",
    "    a = set(classes)\n",
    "    \n",
    "    for i in a:\n",
    "        file.write(str(i)+',')\n",
    "    \n",
    "    file.write('}')    \n",
    "    for i in range(tam):\n",
    "         len(set(classes))\n",
    "    \n",
    "    file.write('\\n@data\\n') \n",
    "\n",
    "    for item in base_teste:\n",
    "        for i in range(len(item)):\n",
    "            file.write(\"%s,\" % str(item[0][i])) \n",
    "        file.write(\"%s\\n\" % item[1])    \n",
    " \n",
    "    file.close()\n",
    "    \n",
    "if(not exist(\"data.arff\")):\n",
    "    gravar_arquivo_arff(arffData,classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
