{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rogeriojunior/gpam/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/rogeriojunior/gpam/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/rogeriojunior/gpam/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/rogeriojunior/gpam/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8248433fccbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;31m# Treinar o classificador\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswrData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpam/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    971\u001b[0m         \"\"\"\n\u001b[1;32m    972\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[0;32m--> 973\u001b[0;31m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpam/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    329\u001b[0m                              hidden_layer_sizes)\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpam/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 910\u001b[0;31m                          multi_output=True)\n\u001b[0m\u001b[1;32m    911\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpam/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/gpam/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Função para facilitar a visualização das imagens\n",
    "def showit(img, openCV=0):\n",
    "    \n",
    "    if(openCV):\n",
    "        cv.imshow(\"t\", img[::4,::4])\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()\n",
    "    \n",
    "    else:  \n",
    "        # Para imagens preto e branco\n",
    "        if(len(img.shape) < 3):\n",
    "            plt.gray()\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.imshow(img[:,:,::-1])\n",
    "            plt.show()\n",
    "\n",
    "# Essa função realça as bordas da imagem\n",
    "def improveEdges(imgCol):\n",
    "    \n",
    "    # Detecção de bordas\n",
    "    sobelVert = cv.Sobel(imgCol, cv.CV_8U, 1, 0, ksize=3)\n",
    "    sobelHori = cv.Sobel(imgCol, cv.CV_8U, 0, 1, ksize=3)\n",
    "    imgColSobel = cv.add(sobelHori, sobelVert)\n",
    "    \n",
    "    # Realçando as bordas encontradas na imagem colorida\n",
    "    stt = cv.getStructuringElement(cv.MORPH_ELLIPSE, (2,2))\n",
    "    imgColSobel = cv.morphologyEx(imgColSobel, cv.MORPH_CLOSE, stt)\n",
    "    \n",
    "    # Adicionar as bordas encontradas na imagem colorida\n",
    "    imgCol = cv.add(imgCol, imgColSobel)\n",
    "    # showit(imgCol, 1)\n",
    "    \n",
    "    return imgCol\n",
    "\n",
    "\n",
    "# Essa função é usada no treinamento do knn\n",
    "def findSingleCoin(imgCol):\n",
    "    \n",
    "# ETAPA 1: ENCONTRAR A REGIÃO DE INTERESSE\n",
    "    \n",
    "    # Reduz tamanho da imagem\n",
    "    # DOTO: Auto resize\n",
    "    imgCol = imgCol[::3,::3]\n",
    "        \n",
    "    # Converter para tons de cinza\n",
    "    imgGray = cv.cvtColor(imgCol, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Encontrar a região de interesse (mascara da região da moeda)\n",
    "    limiar, imgGrayOTSU = cv.threshold(imgGray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU) # limiar de otsu inclui as sombras\n",
    "    ret,imgGray = cv.threshold(imgGray,(limiar-limiar//7) ,255,cv.THRESH_BINARY_INV) # 85% do limiar de otsu\n",
    "\n",
    "    # showit(imgGray,1)\n",
    "\n",
    "    # Parâmetros para selecionar só a região de interesse\n",
    "    val = 11\n",
    "    \n",
    "    # O Esize deve ser no mínimo 5, se não o Dsize fica negativo\n",
    "    Esize = 5\n",
    "    Dsize = (2*Esize) - 7\n",
    "    \n",
    "    # Remover pequenas falhas antes de dilatar\n",
    "    stt = cv.getStructuringElement(cv.MORPH_ELLIPSE, (3,3))\n",
    "    imgBin = cv.erode(imgGray, stt, iterations=1)\n",
    "    # showit(imgBin, 1)\n",
    "\n",
    "    # Fechar buracos na estrutura encontrada\n",
    "    stt = cv.getStructuringElement(cv.MORPH_ELLIPSE, (Dsize,Dsize))\n",
    "    imgBin = cv.morphologyEx(imgBin, cv.MORPH_CLOSE, stt)\n",
    "    imgBin = cv.dilate(imgBin, stt, iterations=val+3)\n",
    "\n",
    "    # showit(imgBin, 1)\n",
    "\n",
    "    # Erosão para remover pequenas falhas e separar moedas coladas\n",
    "    stt = cv.getStructuringElement(cv.MORPH_ELLIPSE, (Esize,Esize))\n",
    "    imgBin = cv.erode(imgBin, stt, iterations=val)\n",
    "\n",
    "    # showit(imgBin, 1)\n",
    "\n",
    "    # Convertendo imgGray para BGR para poder realizar o bitwise\n",
    "    imgGray = cv.cvtColor(imgBin, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Selecionando região de interesse na imagem colorida com a máscara encontrada\n",
    "    imgCol = cv.bitwise_and(imgCol, imgGray)\n",
    "\n",
    "#     showit(imgCol, 1)\n",
    "    \n",
    "# ETAPA 2: REALÇAR AS CARACTERÍSTICAS DA ROI (Bordas e cores)\n",
    "    imgCol = improveEdges(imgCol)\n",
    "    \n",
    "# ETAPA 3: DETECTAR AS MOEDAS\n",
    "\n",
    "    # Achar Contornos das moedas\n",
    "    moedas, hierarquia = cv.findContours(imgBin, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Quantidade de moedas encontradas\n",
    "#     print(len(moedas), \"moedas\")\n",
    "    \n",
    "    # Para cada moeda encontrada\n",
    "    for moeda in moedas:\n",
    "\n",
    "        # Encontre o menor retângulo envolvente\n",
    "        x, y, w, h = cv.boundingRect(moeda)\n",
    "\n",
    "        # Desenhar o retângulo\n",
    "        # cv.rectangle(imgCol, (x,y), (x+w, y+h), (0,255,0), 5)\n",
    "        \n",
    "        # Nova imagem com o menor retângulo envolvente da moeda\n",
    "        imgCoinRoi = imgCol[y:y+h, x:x+w, ::-1]\n",
    "                \n",
    "    return imgCoinRoi\n",
    "\n",
    "def calcHist(imag, roiDefined=False):\n",
    "    \n",
    "    # Find the coin # PROBLEMA\n",
    "    if(not roiDefined):\n",
    "        imag = findSingleCoin(imag)\n",
    "  \n",
    "    b = cv.calcHist([imag[:,:,0]],[0],None,[256],[0,256])\n",
    "    b = cv.normalize(b,b).flatten()\n",
    "    \n",
    "    g = cv.calcHist([imag[:,:,1]],[0],None,[256],[0,256])\n",
    "    g = cv.normalize(g,g).flatten()\n",
    "    \n",
    "    r = cv.calcHist([imag[:,:,2]],[0],None,[256],[0,256])\n",
    "    r = cv.normalize(r,r).flatten()\n",
    "    \n",
    "    result = []\n",
    "    result.append(b.ravel().tolist())\n",
    "    result.append(g.ravel().tolist())\n",
    "    result.append(r.ravel().tolist())\n",
    "    \n",
    "    # Flat the list\n",
    "    result = [y for x in result for y in x]\n",
    "\n",
    "    return result\n",
    "\n",
    "def calcHistFromFile(file):\n",
    "    img = cv2.imread(file)\n",
    "    return calcHist(img)\n",
    "\n",
    "class Enum(tuple):__getattribute__ = tuple.index\n",
    "\n",
    "# ETAPA 1: EXTRAIR CARACTERÍSTICAS DAS IMAGENS\n",
    "Coins = Enum((\"CINCO\", \"DEZ\", \"VINTECINCO\", \"CINQUENTA\", \"REAL\"))\n",
    "\n",
    "# Lista com o nome das imagens nesse diretório\n",
    "sample_images_5_back = glob.glob(\"5/back/*\")\n",
    "sample_images_5_front = glob.glob(\"5/front/*\")\n",
    "\n",
    "sample_images_10_back = glob.glob(\"10/back/*\")\n",
    "sample_images_10_front = glob.glob(\"10/front/*\")\n",
    "\n",
    "sample_images_25_back = glob.glob(\"25/back/*\")\n",
    "sample_images_25_front = glob.glob(\"25/front/*\")\n",
    "\n",
    "sample_images_50_back = glob.glob(\"50/back/*\")\n",
    "sample_images_50_front = glob.glob(\"50/front/*\")\n",
    "\n",
    "sample_images_100_back = glob.glob(\"100/back/*\")\n",
    "sample_images_100_front = glob.glob(\"100/front/*\")\n",
    "\n",
    "# Lista com as características das imagens e suas respectivas classificações\n",
    "data = []\n",
    "answrData = []\n",
    "\n",
    "# Extraindo características das moedas sozinhas\n",
    "for i in sample_images_5_front:\n",
    "    data.append(calcHistFromFile(i))\n",
    "    answrData.append(Coins.CINCO)\n",
    "\n",
    "for i in sample_images_5_back:\n",
    "    data.append(calcHistFromFile(i))\n",
    "    answrData.append(Coins.CINCO)\n",
    "\n",
    "for i in sample_images_10_front:\n",
    "    data.append(calcHistFromFile(i))\n",
    "    answrData.append(Coins.DEZ)\n",
    "\n",
    "for i in sample_images_10_back:\n",
    "    data.append(calcHistFromFile(i))\n",
    "    answrData.append(Coins.DEZ)\n",
    "\n",
    "for i in sample_images_25_front:\n",
    "    data.append(calcHistFromFile(i))\n",
    "    answrData.append(Coins.VINTECINCO)\n",
    "\n",
    "for i in sample_images_25_back:\n",
    "    data.append(calcHistFromFile(i))\n",
    "    answrData.append(Coins.VINTECINCO)\n",
    "\n",
    "for i in sample_images_50_front:\n",
    "    data.append(calcHistFromFile(i))\n",
    "    answrData.append(Coins.CINQUENTA)\n",
    "\n",
    "for i in sample_images_50_back:\n",
    "    data.append(calcHistFromFile(i))\n",
    "    answrData.append(Coins.CINQUENTA)\n",
    "\n",
    "for i in sample_images_100_front:\n",
    "    data.append(calcHistFromFile(i))\n",
    "    answrData.append(Coins.REAL)\n",
    "\n",
    "for i in sample_images_100_back:\n",
    "    data.append(calcHistFromFile(i))\n",
    "    answrData.append(Coins.REAL)\n",
    "\n",
    "# Classificador que será usado\n",
    "clf = MLPClassifier(solver=\"lbfgs\")\n",
    "\n",
    "# Treinar o classificador\n",
    "clf.fit(data, answrData)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "cv = cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def predictCoin(roi):\n",
    "    hist = calcHist(roi, True)\n",
    "    s = clf.predict([hist])\n",
    "    \n",
    "    return Coins[int(s)]\n",
    "\n",
    "def findMultiplesCoin(imgCol):\n",
    "    img = cv.cvtColor(imgCol, cv.COLOR_BGR2GRAY)\n",
    "    img = improveEdges(img)\n",
    "    img = cv2.blur(img, (3,3))\n",
    "\n",
    "    # Single channel to multiples channel\n",
    "    cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    circles = cv2.HoughCircles(img,method=cv2.HOUGH_GRADIENT,dp=1,minDist=116,\n",
    "                               param1=60,param2=60,minRadius=50,maxRadius=90)\n",
    "    return circles\n",
    "\n",
    "# Imagem que será analisada\n",
    "img = cv.imread(\"juntas/5front-5front-50back-25back-25back-5back-5front-5front-50back-10front-5back-10front-50front-5back-10front-10front-100front-100front-50front.jpg\")[::3,::3]\n",
    "\n",
    "# Cópia da imagem original que será apresentada no final\n",
    "output = img.copy()\n",
    "\n",
    "circles = findMultiplesCoin(img)\n",
    "\n",
    "count = 0\n",
    "if circles is not None:\n",
    "    # coordinates and radii\n",
    "    circles = np.round(circles[0,:]).astype(int)\n",
    "    \n",
    "    for (x, y, d) in circles:\n",
    "        count += 1\n",
    "                \n",
    "        roi = img[y-d:y+d, x-d:x+d]\n",
    "        \n",
    "        roi = improveEdges(roi)\n",
    "        \n",
    "        coin = predictCoin(roi)\n",
    "        \n",
    "        cv.circle(output, (x,y), d, (0, 255, 0), 2)\n",
    "        cv.putText(output, coin, (x - 40, y), cv2.FONT_HERSHEY_PLAIN, \n",
    "                   1.5, (0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "cv.imshow(\"t\", output[::2,::2,:])\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
