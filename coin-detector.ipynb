{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coin Accounter System "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import isfile as exist\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import itemfreq\n",
    "from pylab import arange, array\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import warnings\n",
    "import pickle\n",
    "import glob\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para facilitar a visualização das imagens\n",
    "def showit(img, openCV=0, text='t'):\n",
    "    \n",
    "    if(openCV):\n",
    "        cv.imshow(text, img)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()\n",
    "    \n",
    "    else:  \n",
    "        # Para imagens preto e branco\n",
    "        if(len(img.shape) < 3):\n",
    "            plt.gray()\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.imshow(img[:,:,::-1])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improveTexture(img):\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img = clahe.apply(img)\n",
    "    return img\n",
    "\n",
    "def resize(img, cols=800):    \n",
    "    d = cols / img.shape[1]\n",
    "    dim = (cols, int(img.shape[0] * d))\n",
    "    img = cv.resize(img, dim, interpolation=cv.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Coin ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleCount = 0\n",
    "\n",
    "# Função que retorna a mascara das moedas na imagem\n",
    "def getMask(img):\n",
    "    \n",
    "    a, b = -1/4, 4\n",
    "    kernel = np.array([[a,a,a],[a,b,a],[a,a,a]])\n",
    "    img = cv.filter2D(img,-1,kernel)\n",
    "    img = cv.bitwise_not(img, img)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    limiar, img = cv.threshold(img, 30, 255, cv.THRESH_BINARY) # limiar de otsu inclui as sombras\n",
    "    \n",
    "    stt = cv.getStructuringElement(cv.MORPH_ELLIPSE, (11,11))\n",
    "    mask = cv.morphologyEx(img, cv.MORPH_CLOSE, stt, iterations=7)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# Função que encontrar a moeda na imagem e retorna o menor quadrado envolvente com a moeda\n",
    "def findSingleCoin(imgCol):\n",
    "    \n",
    "    # Reduz tamanho da imagem\n",
    "    imgCol = resize(imgCol, 800)\n",
    "    \n",
    "#     showit(imgCol, 1)\n",
    "    \n",
    "    # Encontro a Região de Interesse\n",
    "    imgBin = getMask(imgCol)\n",
    "\n",
    "    # Selecionando região de interesse na imagem colorida com a máscara encontrada\n",
    "    imgCol = cv.bitwise_and(imgCol, imgCol, mask=imgBin)\n",
    "    \n",
    "#     showit(imgCol, 1)\n",
    "    \n",
    "    # Achar contornos das moedas\n",
    "    moedas, hierarquia = cv.findContours(imgBin, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "    # Para cada moeda encontrada\n",
    "    for moeda in moedas:\n",
    "        \n",
    "        # Não contabilizar regiões de falhas\n",
    "        area = cv.contourArea(moeda)\n",
    "        if(area < 5000.0):            \n",
    "            continue\n",
    "            \n",
    "        # Encontre o menor retângulo envolvente\n",
    "        x, y, w, h = cv.boundingRect(moeda)\n",
    "\n",
    "        # Nova imagem com o menor retângulo envolvente da moeda\n",
    "        imgCoinRoi = imgCol[y:y+h, x:x+w]\n",
    "        \n",
    "        # Writing results in results folder\n",
    "        global singleCount\n",
    "        singleCount += 1\n",
    "        cv.imwrite(\"singleCoins/coin{}.png\".format(singleCount), imgCoinRoi)\n",
    "\n",
    "#         showit(imgCoinRoi)\n",
    "        \n",
    "        return imgCoinRoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractions Functions Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp(img):\n",
    "    \n",
    "    if(len(img.shape) > 2):\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "    qtdeLinhas, qtdeColunas = img.shape\n",
    "    out = img.copy()\n",
    "    \n",
    "    for i in range(1,qtdeLinhas-1):\n",
    "        for j in range(1,qtdeColunas-1):                \n",
    "            a=img[i-1,j]\n",
    "            b=img[i-1,j+1]\n",
    "            c=img[i,j+1]\n",
    "            d=img[i+1,j+1]\n",
    "            e=img[i+1,j]\n",
    "            f=img[i+1,j-1]\n",
    "            g=img[i,j-1]\n",
    "            h=img[i-1,j-1]\n",
    "            centro=img[i,j]\n",
    "            \n",
    "            soma=0\n",
    "            \n",
    "            if(a<centro):\n",
    "                soma = soma + 2**7\n",
    "            if(b<centro):\n",
    "                soma = soma + 2**6\n",
    "            if(c<centro):\n",
    "                soma = soma + 2**5\n",
    "            if(d<centro):\n",
    "                soma = soma + 2**4\n",
    "            if(e<centro):\n",
    "                soma = soma + 2**3\n",
    "            if(f<centro):\n",
    "                soma = soma + 2**2\n",
    "            if(g<centro):\n",
    "                soma = soma + 2**1\n",
    "            if(h<centro):\n",
    "                soma = soma + 2**0\n",
    "\n",
    "            out[i,j]=soma\n",
    "    \n",
    "#     showit(out, 1, 'lbp')\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increaseSaturation(img):\n",
    "    \n",
    "    # CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    clahe = cv.createCLAHE(clipLimit=3., tileGridSize=(8,8))\n",
    "\n",
    "    # convert from BGR to LAB color space\n",
    "    lab = cv.cvtColor(img, cv.COLOR_BGR2LAB)\n",
    "    l, a, b = cv.split(lab)\n",
    "\n",
    "    # apply CLAHE to the L-channel\n",
    "    l2 = clahe.apply(l)\n",
    "\n",
    "    lab = cv.merge((l2,a,b))\n",
    "    img = cv.cvtColor(lab, cv.COLOR_LAB2BGR)\n",
    "\n",
    "    maxIntensity = 255.0\n",
    "    x = arange(maxIntensity)\n",
    "    img = (maxIntensity/1)*(img/(maxIntensity/1))**2\n",
    "    img = array(img,dtype=np.uint8)\n",
    "    \n",
    "#     showit(img, 1)\n",
    "    \n",
    "    return img\n",
    "    \n",
    "def saturationHistogram(img):\n",
    "    img = increaseSaturation(img)\n",
    "    hist = cv.calcHist([img],[0],None,[256],[0,256])\n",
    "    hist = [float(i)/max(hist) for i in hist]\n",
    "    \n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coloredHistogram(img):\n",
    "    \n",
    "    histBlue = cv.calcHist([img[:,:,0]],[0],None,[256],[0,256])\n",
    "    histBlue = [float(i)/max(histBlue) for i in histBlue]    \n",
    "    \n",
    "    histGreen = cv.calcHist([img[:,:,1]],[0],None,[256],[0,256])\n",
    "    histGreen = [float(i)/max(histGreen) for i in histGreen]    \n",
    "    \n",
    "    histRed = cv.calcHist([img[:,:,2]],[0],None,[256],[0,256])\n",
    "    histRed = [float(i)/max(histRed) for i in histRed]\n",
    "    \n",
    "    for i in range(len(histBlue)):\n",
    "        histBlue[i] = min(histBlue[i], histGreen[i], histRed[i])\n",
    "        \n",
    "    return histBlue.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograma(img):\n",
    "    hist = cv.calcHist([img],[0],None,[256],[0,256])\n",
    "    hist = [float(i)/max(hist) for i in hist]\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_orb(img, NCLUST = 10):\n",
    "    \n",
    "    def distancia(a, b):\n",
    "        soma = 0\n",
    "        for i in range(len(a)):\n",
    "            soma = soma + ((a[i]-b[i])**2)\n",
    "        return np.sqrt(soma) \n",
    "    \n",
    "    orb = cv.ORB_create()\n",
    "    kp = orb.detect(img,None)\n",
    "    kp, des = orb.compute(img, kp)\n",
    "    \n",
    "    kmeans_model = KMeans(n_clusters=NCLUST).fit(des)\n",
    "        \n",
    "    palavras = np.array(kmeans_model.cluster_centers_)\n",
    "    \n",
    "    pontos_rotulados = []\n",
    "    \n",
    "    for ponto in des:\n",
    "        minim = 9999\n",
    "        label = -1\n",
    "        \n",
    "        for i in range(len(palavras)):\n",
    "            dist = distancia(ponto, palavras[i])\n",
    "            \n",
    "            if(dist < minim):\n",
    "                minim = dist\n",
    "                label = i\n",
    "\n",
    "        pontos_rotulados.append(label)\n",
    "        \n",
    "    hist = np.zeros(NCLUST)\n",
    "\n",
    "    for i in pontos_rotulados:\n",
    "        hist[i] += 1\n",
    "        \n",
    "    hist = [float(i)/max(hist) for i in hist]\n",
    "            \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(imag, roiDefined=False):\n",
    "    \n",
    "    if(not roiDefined):\n",
    "        imag = findSingleCoin(imag)\n",
    "    \n",
    "    # LBP Invariant\n",
    "    img = cv.cvtColor(imag.copy(), cv.COLOR_BGR2GRAY)\n",
    "    lbp = local_binary_pattern(img,8,2,method='uniform')\n",
    "    lbp_hist = itemfreq(lbp).flatten()\n",
    "    lbp_hist = [float(i)/max(lbp_hist) for i in lbp_hist]\n",
    "    \n",
    "    return lbp_hist\n",
    "    \n",
    "    # Bag of Features -> Demorado e piora o classificador\n",
    "#     orb_hist = hist_orb(imag.copy(), 50)\n",
    "    \n",
    "#     return np.append(lbp_hist, orb_hist)\n",
    "        \n",
    "def extractionFromFile(file):\n",
    "    img = cv.imread(file)\n",
    "    return extraction(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.07091927528381348 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "class Enum(tuple):__getattribute__ = tuple.index\n",
    "classes = ['0', '1', '2', '3', '4']\n",
    "\n",
    "# ETAPA 1: EXTRAIR CARACTERÍSTICAS DAS IMAGENS\n",
    "Coins = Enum((\"CINCO\", \"DEZ\", \"VINTECINCO\", \"CINQUENTA\", \"REAL\"))\n",
    "\n",
    "if(exist(\"coin_features\") and exist(\"coin_features_answer\")):\n",
    "    \n",
    "    with open('coin_features', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    with open('coin_features_answer', 'rb') as f:\n",
    "        answrData = pickle.load(f)\n",
    "    \n",
    "    with open('ArffData', 'rb') as f:\n",
    "        arffData = pickle.load(f)\n",
    "        \n",
    "else:\n",
    "    \n",
    "    # Defina onde está a pasta do dataset da moeda\n",
    "    coin_directory = \"datacoins/\"\n",
    "\n",
    "    # Lista com o nome das imagens nesse diretório\n",
    "    sample_images_5_back = glob.glob(coin_directory + \"5/back/*\")\n",
    "    sample_images_5_front = glob.glob(coin_directory + \"5/front/*\")\n",
    "\n",
    "    sample_images_10_back = glob.glob(coin_directory  + \"10/back/*\")\n",
    "    sample_images_10_front = glob.glob(coin_directory + \"10/front/*\")\n",
    "\n",
    "    sample_images_25_back = glob.glob(coin_directory  + \"25/back/*\")\n",
    "    sample_images_25_front = glob.glob(coin_directory + \"25/front/*\")\n",
    "\n",
    "    sample_images_50_back = glob.glob(coin_directory  + \"50/back/*\")\n",
    "    sample_images_50_front = glob.glob(coin_directory + \"50/front/*\")\n",
    "\n",
    "    sample_images_100_back = glob.glob(coin_directory  + \"100/back/*\")\n",
    "    sample_images_100_front = glob.glob(coin_directory + \"100/front/*\")\n",
    "\n",
    "    # Lista com as características das imagens e suas respectivas classificações\n",
    "    data = []\n",
    "    answrData = []\n",
    "    arffData = []\n",
    "    \n",
    "    qntFailure = 0\n",
    "    FailureList = []\n",
    "    \n",
    "    # Extraindo características das moedas sozinhas\n",
    "    for i in sample_images_5_front:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(Coins.CINCO)\n",
    "            arffData.append((features, str(Coins.CINCO)))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_5_back:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(Coins.CINCO)\n",
    "            arffData.append((features, str(Coins.CINCO)))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_10_front:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(Coins.DEZ)\n",
    "            arffData.append((features, str(Coins.DEZ)))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_10_back:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(Coins.DEZ)\n",
    "            arffData.append((features, str(Coins.DEZ)))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_25_front:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(Coins.VINTECINCO)\n",
    "            arffData.append((features, str(Coins.VINTECINCO)))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_25_back:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(Coins.VINTECINCO)\n",
    "            arffData.append((features, str(Coins.VINTECINCO)))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_50_front:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(Coins.CINQUENTA)\n",
    "            arffData.append((features, str(Coins.CINQUENTA)))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_50_back:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(Coins.CINQUENTA)\n",
    "            arffData.append((features, str(Coins.CINQUENTA)))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_100_front:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(Coins.REAL)\n",
    "            arffData.append((features, str(Coins.REAL))) \n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "\n",
    "    for i in sample_images_100_back:\n",
    "        try:\n",
    "            features = extractionFromFile(i)\n",
    "            data.append(features)\n",
    "            answrData.append(Coins.REAL)\n",
    "            arffData.append((features, str(Coins.REAL)))\n",
    "        except:\n",
    "            FailureList.append(i)\n",
    "            qntFailure += 1\n",
    "            continue\n",
    "    \n",
    "    c = 0  \n",
    "    for i in FailureList:\n",
    "        img = cv.imread(i)\n",
    "        c += 1\n",
    "        cv.imwrite(\"fail_img/coin{}.png\".format(c), img)\n",
    "    \n",
    "    print(qntFailure, \"imagens falharam na extração de características\")\n",
    "\n",
    "    # Save the results\n",
    "    with open('coin_features', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "    with open('coin_features_answer', 'wb') as f:\n",
    "        pickle.dump(answrData, f)\n",
    "    \n",
    "    with open('ArffData', 'wb') as f:\n",
    "        pickle.dump(arffData, f)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 75% para treino, 25% da medir a accuracia\n",
    "data_train, data_test, asw_train, asw_test = train_test_split(\n",
    "    data, answrData, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier mean accuracy:  85 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "trReg = DecisionTreeRegressor().fit(data_train,asw_train)\n",
    "# t.predict(test)\n",
    "\n",
    "score = int(trReg.score(data_test, asw_test) * 100)\n",
    "print(\"Classifier mean accuracy: \", score, \"%\")\n",
    "trReg = DecisionTreeRegressor().fit(data,answrData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier mean accuracy:  34 %\n",
      "--- 1.8646488189697266 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "start_time = time.time()\n",
    "\n",
    "mlp = MLPClassifier(solver=\"lbfgs\").fit(data_train,asw_train)\n",
    "\n",
    "score = int(mlp.score(data_test, asw_test) * 100)\n",
    "print(\"Classifier mean accuracy: \", score, \"%\")\n",
    "mlp = MLPClassifier(solver=\"lbfgs\").fit(data,answrData)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier mean accuracy:  91 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50).fit(data_train,asw_train)\n",
    "# clf.predict(test)\n",
    "\n",
    "score = int(clf.score(data_test, asw_test) * 100)\n",
    "print(\"Classifier mean accuracy: \", score, \"%\")\n",
    "clf = RandomForestClassifier(n_estimators=50, bootstrap = True, max_features = 'sqrt').fit(data_train,asw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier mean accuracy:  89 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier().fit(data_train,asw_train)\n",
    "# tree.predict()\n",
    "\n",
    "score = int(tree.score(data_test, asw_test) * 100)\n",
    "print(\"Classifier mean accuracy: \", score, \"%\")\n",
    "tree = DecisionTreeClassifier().fit(data_train,asw_train).fit(data,answrData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecione qual classificador será usado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = trReg  # DecisionTreeRegressor\n",
    "# classifier = tree   # DecisionTreeClassifier\n",
    "classifier = clf    # RandomForestClassifier\n",
    "# classifier = mlp    # MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predictCoin(roi):\n",
    "        \n",
    "    hist = extraction(roi, True)\n",
    "    s = classifier.predict([hist])\n",
    "    \n",
    "    # Lista com as probabilidade de cada moeda\n",
    "    a = classifier.predict_proba([hist]).tolist()\n",
    "        \n",
    "    return Coins[a[0].index(max(a[0]))], max(a[0])\n",
    "\n",
    "def getMask(img, RoiDefined=False):\n",
    "    \n",
    "    a, b = -1/4, 4\n",
    "    kernel = np.array([[a,a,a],[a,b,a],[a,a,a]])\n",
    "    img = cv.filter2D(img,-1,kernel)\n",
    "    img = cv.bitwise_not(img, img)\n",
    "    \n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    limiar, img = cv.threshold(img, 0, 255, cv.THRESH_BINARY) # limiar de otsu inclui as sombras\n",
    "        \n",
    "    if(RoiDefined):\n",
    "        size=2\n",
    "        times=15\n",
    "    else:\n",
    "        size=5\n",
    "        times=20\n",
    "    \n",
    "    stt = cv.getStructuringElement(cv.MORPH_ELLIPSE, (size,size))\n",
    "    mask = cv.morphologyEx(img, cv.MORPH_CLOSE, stt, iterations=times)\n",
    "        \n",
    "#     showit(mask,1)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def findMultiplesCoin(imgCol):\n",
    "    \n",
    "    imgBin = getMask(imgCol)\n",
    "    imgCol = cv.bitwise_and(imgCol, imgCol, mask=imgBin)\n",
    "        \n",
    "    img = cv.cvtColor(imgCol, cv.COLOR_BGR2GRAY)\n",
    "    img = cv.bilateralFilter(img, 5, 90, 90)\n",
    "        \n",
    "#     showit(img, 1)\n",
    "    \n",
    "    circles = cv.HoughCircles(img,method=cv.HOUGH_GRADIENT,dp=1,minDist=110,\n",
    "                               param1=50,param2=50,minRadius=30,maxRadius=80)\n",
    "    \n",
    "    return circles\n",
    "\n",
    "# Imagem que será analisada\n",
    "ct = 0\n",
    "def coin_detector(img):\n",
    "    img = resize(img, 800)\n",
    "    output = img.copy()\n",
    "\n",
    "    a, b = -1/4, 4\n",
    "    kernel = np.array([[a,a,a],[a,b,a],[a,a,a]])\n",
    "    img = cv.filter2D(img,-1,kernel)\n",
    "    \n",
    "#     showit(img, 1)\n",
    "\n",
    "    circles = findMultiplesCoin(img)\n",
    "\n",
    "    form = img.copy()\n",
    "    \n",
    "    listCoins = []\n",
    "\n",
    "    count = 0\n",
    "    if circles is not None:\n",
    "        \n",
    "        # coordinates and radii\n",
    "        circles = np.round(circles[0,:]).astype(int)\n",
    "\n",
    "        for (x, y, d) in circles:\n",
    "\n",
    "            count += 1 # Qnt de moedas\n",
    "#             d+=7 # Increase radius\n",
    "\n",
    "            form[:,:,:]=0\n",
    "\n",
    "            cv.circle(form,(x,y), d, (255,255,255), -1)\n",
    "            img2gray = cv.cvtColor(form, cv.COLOR_BGR2GRAY)\n",
    "            ret, imgBin = cv.threshold(img2gray, 0, 255, cv.THRESH_BINARY)\n",
    "\n",
    "#             showit(form,1)\n",
    "\n",
    "            roi = cv.bitwise_and(img, img, mask=imgBin)\n",
    "            roi = roi[y-d:y+d, x-d:x+d]\n",
    "        \n",
    "            listCoins.append(roi)\n",
    "\n",
    "#             showit(roi[::2,::2],1)\n",
    "\n",
    "            coin, chance = predictCoin(roi)\n",
    "\n",
    "            chance = str(int(chance*100)) + \" %\"\n",
    "\n",
    "            cv.circle(output, (x,y), d, (0, 255, 0), 2)\n",
    "            cv.putText(output, coin, (x - 40, y), cv.FONT_HERSHEY_PLAIN,\n",
    "                       1.5, (0, 255, 0), thickness=2, lineType=cv.LINE_AA)\n",
    "\n",
    "            cv.putText(output, chance, (x - 20, y+30), cv.FONT_HERSHEY_PLAIN,\n",
    "                       1.5, (0, 255, 0), thickness=2, lineType=cv.LINE_AA)\n",
    "    \n",
    "#     showit(output, 1)\n",
    "    global ct\n",
    "    ct += 1\n",
    "    cv.imwrite(\"final_result/coin{}.png\".format(ct), output)\n",
    "    \n",
    "    return listCoins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = glob.glob('datacoins/juntas/*')\n",
    "\n",
    "count = 0\n",
    "\n",
    "for file in sample:\n",
    "    img = cv.imread(file)\n",
    "    \n",
    "    listCoins = coin_detector(img)\n",
    "    \n",
    "#     for img in listCoins:\n",
    "#         count += 1\n",
    "#         cv.imwrite(\"results/coin{}.png\".format(count), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivo ARFF para testar no Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile as exist\n",
    "\n",
    "def gravar_arquivo_arff(base_teste, classes):\n",
    "    tam = len(base_teste[0])\n",
    "    file = open('data.arff','w') \n",
    " \n",
    "    file.write('@relation teste\\n') \n",
    "    for i in range(tam):\n",
    "        file.write('@attribute '+ str(i) +' NUMERIC\\n') \n",
    "    \n",
    "    file.write('@attribute classes {')\n",
    "    \n",
    "    a = set(classes)\n",
    "    \n",
    "    for i in a:\n",
    "        file.write(str(i)+',')\n",
    "    \n",
    "    file.write('}')    \n",
    "    for i in range(tam):\n",
    "         len(set(classes))\n",
    "    \n",
    "    file.write('\\n@data\\n') \n",
    "\n",
    "    for item in base_teste:\n",
    "        for i in range(len(item)):\n",
    "            file.write(\"%s,\" % str(item[0][i])) \n",
    "        file.write(\"%s\\n\" % item[1])    \n",
    " \n",
    "    file.close()\n",
    "    \n",
    "if(not exist(\"data.arff\")):\n",
    "    gravar_arquivo_arff(arffData,classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
