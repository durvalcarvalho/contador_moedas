{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coin Accounter System "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para facilitar a visualização das imagens\n",
    "def showit(img, openCV=0, text='t'):\n",
    "    \n",
    "    if(openCV):\n",
    "        cv.imshow(text, img[::2,::2])\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()\n",
    "    \n",
    "    else:  \n",
    "        # Para imagens preto e branco\n",
    "        if(len(img.shape) < 3):\n",
    "            plt.gray()\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.imshow(img[:,:,::-1])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improveTexture(img):\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img = clahe.apply(img)\n",
    "    return img\n",
    "\n",
    "def resize(img, cols=800):    \n",
    "    d = cols / img.shape[1]\n",
    "    dim = (cols, int(img.shape[0] * d))\n",
    "    img = cv.resize(img, dim, interpolation=cv.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Coin ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que retorna a mascara das moedas na imagem\n",
    "def getMask(img):\n",
    "    \n",
    "    a, b = -1/4, 4\n",
    "    kernel = np.array([[a,a,a],[a,b,a],[a,a,a]])\n",
    "    img = cv.filter2D(img,-1,kernel)\n",
    "    img = cv.bitwise_not(img, img)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    limiar, img = cv.threshold(img, 30, 255, cv.THRESH_BINARY) # limiar de otsu inclui as sombras\n",
    "    \n",
    "    stt = cv.getStructuringElement(cv.MORPH_ELLIPSE, (13,13))\n",
    "    mask = cv.morphologyEx(img, cv.MORPH_CLOSE, stt, iterations=5)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# Função que encontrar a moeda na imagem e retorna o menor quadrado envolvente com a moeda\n",
    "def findSingleCoin(imgCol):\n",
    "    \n",
    "    # Reduz tamanho da imagem\n",
    "    imgCol = resize(imgCol, 800)\n",
    "    \n",
    "#     showit(imgCol, 1)\n",
    "    \n",
    "    # Encontro a Região de Interesse\n",
    "    imgBin = getMask(imgCol)\n",
    "\n",
    "    # Selecionando região de interesse na imagem colorida com a máscara encontrada\n",
    "    imgCol = cv.bitwise_and(imgCol, imgCol, mask=imgBin)\n",
    "    \n",
    "#     showit(imgCol, 1)\n",
    "    \n",
    "    # Achar contornos das moedas\n",
    "    moedas, hierarquia = cv.findContours(imgBin, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "    # Para cada moeda encontrada\n",
    "    for moeda in moedas:\n",
    "        \n",
    "        # Não contabilizar regiões de falhas\n",
    "        area = cv.contourArea(moeda)\n",
    "        if(area < 5000.0):            \n",
    "            continue\n",
    "            \n",
    "        # Encontre o menor retângulo envolvente\n",
    "        x, y, w, h = cv.boundingRect(moeda)\n",
    "\n",
    "        # Nova imagem com o menor retângulo envolvente da moeda\n",
    "        imgCoinRoi = imgCol[y:y+h, x:x+w]\n",
    "\n",
    "#         showit(imgCoinRoi)\n",
    "        \n",
    "        return imgCoinRoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractions Functions Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp(img):\n",
    "    qtdeLinhas, qtdeColunas = img.shape\n",
    "    out = img.copy()\n",
    "    \n",
    "    for i in range(1,qtdeLinhas-1):\n",
    "        for j in range(1,qtdeColunas-1):                \n",
    "            a=img[i-1,j]\n",
    "            b=img[i-1,j+1]\n",
    "            c=img[i,j+1]\n",
    "            d=img[i+1,j+1]\n",
    "            e=img[i+1,j]\n",
    "            f=img[i+1,j-1]\n",
    "            g=img[i,j-1]\n",
    "            h=img[i-1,j-1]\n",
    "            centro=img[i,j]\n",
    "            \n",
    "            soma=0\n",
    "            \n",
    "            if(a<centro):\n",
    "                soma = soma + 2**7\n",
    "            if(b<centro):\n",
    "                soma = soma + 2**6\n",
    "            if(c<centro):\n",
    "                soma = soma + 2**5\n",
    "            if(d<centro):\n",
    "                soma = soma + 2**4\n",
    "            if(e<centro):\n",
    "                soma = soma + 2**3\n",
    "            if(f<centro):\n",
    "                soma = soma + 2**2\n",
    "            if(g<centro):\n",
    "                soma = soma + 2**1\n",
    "            if(h<centro):\n",
    "                soma = soma + 2**0\n",
    "\n",
    "            out[i,j]=soma\n",
    "    \n",
    "#     showit(out, 1, 'lbp')\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saturationHistogram(img):\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2HSV)    \n",
    "    hist = cv.calcHist([img],[0],None,[256],[0,256])\n",
    "    hist = cv.normalize(hist, None)\n",
    "    \n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coloredHistogram(img):\n",
    "    \n",
    "    histBlue = cv.calcHist([img[:,:,0]],[0],None,[256],[0,256])\n",
    "    histBlue = cv.normalize(histBlue, None)\n",
    "    \n",
    "    histGreen = cv.calcHist([img[:,:,1]],[0],None,[256],[0,256])\n",
    "    histGreen = cv.normalize(histGreen, None)\n",
    "    \n",
    "    histRed = cv.calcHist([img[:,:,2]],[0],None,[256],[0,256])\n",
    "    histRed = cv.normalize(histRed, None)\n",
    "    \n",
    "    for i in range(len(histBlue)):\n",
    "        histBlue[i] = min(histBlue[i], histGreen[i], histRed[i])\n",
    "        \n",
    "    return histBlue.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograma(img):\n",
    "    hist = cv.calcHist([img],[0],None,[256],[0,256])\n",
    "    hist = cv.normalize(hist, None)\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(imag, roiDefined=False):\n",
    "    \n",
    "    if(not roiDefined):\n",
    "        imag = findSingleCoin(imag)\n",
    "\n",
    "    color = coloredHistogram(imag)\n",
    "    saturation = saturationHistogram(imag)\n",
    "\n",
    "    imag = improveTexture(imag)\n",
    "    imag = lbp(imag)\n",
    "    texture = histograma(imag)\n",
    "    \n",
    "    return np.append(np.append(texture, color), saturation)\n",
    "\n",
    "def extractionFromFile(file):\n",
    "    img = cv.imread(file)\n",
    "    return extraction(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.00603485107421875 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from os.path import isfile as exist\n",
    "start_time = time.time()\n",
    "\n",
    "class Enum(tuple):__getattribute__ = tuple.index\n",
    "\n",
    "# ETAPA 1: EXTRAIR CARACTERÍSTICAS DAS IMAGENS\n",
    "Coins = Enum((\"CINCO\", \"DEZ\", \"VINTECINCO\", \"CINQUENTA\", \"REAL\"))\n",
    "\n",
    "if(exist(\"coin_features\") and exist(\"coin_features_answer\")):\n",
    "    \n",
    "    with open('coin_features', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    with open('coin_features_answer', 'rb') as f:\n",
    "        answrData = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    \n",
    "    # Defina onde está a pasta do dataset da moeda\n",
    "    coin_directory = \"datacoins/\"\n",
    "\n",
    "    # Lista com o nome das imagens nesse diretório\n",
    "    sample_images_5_back = glob.glob(coin_directory + \"5/back/*\")\n",
    "    sample_images_5_front = glob.glob(coin_directory + \"5/front/*\")\n",
    "\n",
    "    sample_images_10_back = glob.glob(coin_directory  + \"10/back/*\")\n",
    "    sample_images_10_front = glob.glob(coin_directory + \"10/front/*\")\n",
    "\n",
    "    sample_images_25_back = glob.glob(coin_directory  + \"25/back/*\")\n",
    "    sample_images_25_front = glob.glob(coin_directory + \"25/front/*\")\n",
    "\n",
    "    sample_images_50_back = glob.glob(coin_directory  + \"50/back/*\")\n",
    "    sample_images_50_front = glob.glob(coin_directory + \"50/front/*\")\n",
    "\n",
    "    sample_images_100_back = glob.glob(coin_directory  + \"100/back/*\")\n",
    "    sample_images_100_front = glob.glob(coin_directory + \"100/front/*\")\n",
    "\n",
    "    # Lista com as características das imagens e suas respectivas classificações\n",
    "    data = []\n",
    "    answrData = []\n",
    "    arffData = []\n",
    "    classes = ['0', '1', '2', '3', '4']\n",
    "\n",
    "    # Extraindo características das moedas sozinhas\n",
    "    for i in sample_images_5_front:\n",
    "        features = extractionFromFile(i)\n",
    "        data.append(features)\n",
    "        answrData.append(Coins.CINCO)\n",
    "\n",
    "        arffData.append((features, str(Coins.CINCO)))\n",
    "\n",
    "    for i in sample_images_5_back:\n",
    "        features = extractionFromFile(i)\n",
    "        data.append(features)\n",
    "        answrData.append(Coins.CINCO)\n",
    "\n",
    "        arffData.append((features, str(Coins.CINCO)))\n",
    "\n",
    "    for i in sample_images_10_front:\n",
    "        features = extractionFromFile(i)\n",
    "        data.append(features)\n",
    "        answrData.append(Coins.DEZ)\n",
    "\n",
    "        arffData.append((features, str(Coins.DEZ)))\n",
    "\n",
    "    for i in sample_images_10_back:\n",
    "        features = extractionFromFile(i)\n",
    "        data.append(features)\n",
    "        answrData.append(Coins.DEZ)\n",
    "\n",
    "        arffData.append((features, str(Coins.DEZ)))\n",
    "\n",
    "    for i in sample_images_25_front:\n",
    "        features = extractionFromFile(i)\n",
    "        data.append(features)\n",
    "        answrData.append(Coins.VINTECINCO)\n",
    "\n",
    "        arffData.append((features, str(Coins.VINTECINCO)))\n",
    "\n",
    "    for i in sample_images_25_back:\n",
    "        features = extractionFromFile(i)\n",
    "        data.append(features)\n",
    "        answrData.append(Coins.VINTECINCO)\n",
    "\n",
    "        arffData.append((features, str(Coins.VINTECINCO)))\n",
    "\n",
    "    for i in sample_images_50_front:\n",
    "        features = extractionFromFile(i)\n",
    "        data.append(features)\n",
    "        answrData.append(Coins.CINQUENTA)\n",
    "\n",
    "        arffData.append((features, str(Coins.CINQUENTA)))\n",
    "\n",
    "    for i in sample_images_50_back:\n",
    "        features = extractionFromFile(i)\n",
    "        data.append(features)\n",
    "        answrData.append(Coins.CINQUENTA)\n",
    "\n",
    "        arffData.append((features, str(Coins.CINQUENTA)))\n",
    "\n",
    "    for i in sample_images_100_front:\n",
    "        features = extractionFromFile(i)\n",
    "        data.append(features)\n",
    "        answrData.append(Coins.REAL)\n",
    "\n",
    "        arffData.append((features, str(Coins.REAL))) \n",
    "\n",
    "    for i in sample_images_100_back:\n",
    "        features = extractionFromFile(i)\n",
    "        data.append(features)\n",
    "        answrData.append(Coins.REAL)\n",
    "\n",
    "        arffData.append((features, str(Coins.REAL)))\n",
    "\n",
    "    # Save the results\n",
    "    with open('coin_features', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "    with open('coin_features_answer', 'wb') as f:\n",
    "        pickle.dump(answrData, f)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 75% para treino, 25% da medir a accuracia\n",
    "data_train, data_test, asw_train, asw_test = train_test_split(\n",
    "    data, answrData, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier mean accuracy:  89 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "trReg = DecisionTreeRegressor().fit(data_train,asw_train)\n",
    "# t.predict(test)\n",
    "\n",
    "score = int(trReg.score(data_test, asw_test) * 100)\n",
    "print(\"Classifier mean accuracy: \", score, \"%\")\n",
    "trReg = DecisionTreeRegressor().fit(data,answrData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier mean accuracy:  95 %\n",
      "--- 15.949693202972412 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "start_time = time.time()\n",
    "\n",
    "mlp = MLPClassifier(solver=\"lbfgs\").fit(data_train,asw_train)\n",
    "\n",
    "score = int(mlp.score(data_test, asw_test) * 100)\n",
    "print(\"Classifier mean accuracy: \", score, \"%\")\n",
    "mlp = MLPClassifier(solver=\"lbfgs\").fit(data,answrData)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier mean accuracy:  96 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50).fit(data_train,asw_train)\n",
    "# clf.predict(test)\n",
    "\n",
    "score = int(clf.score(data_test, asw_test) * 100)\n",
    "print(\"Classifier mean accuracy: \", score, \"%\")\n",
    "clf = RandomForestClassifier(n_estimators=50, bootstrap = True, max_features = 'sqrt').fit(data_train,asw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier mean accuracy:  94 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier().fit(data_train,asw_train)\n",
    "# tree.predict()\n",
    "\n",
    "score = int(tree.score(data_test, asw_test) * 100)\n",
    "print(\"Classifier mean accuracy: \", score, \"%\")\n",
    "tree = DecisionTreeClassifier().fit(data_train,asw_train).fit(data,answrData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = trReg\n",
    "# classifier = tree\n",
    "classifier = clf\n",
    "# classifier = mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predictCoin(roi):\n",
    "    hist = extraction(roi, True)\n",
    "    s = classifier.predict([hist])\n",
    "    \n",
    "    # Lista com as probabilidade de cada moeda\n",
    "    a = classifier.predict_proba([hist]).tolist()\n",
    "        \n",
    "    return Coins[a[0].index(max(a[0]))], max(a[0])\n",
    "\n",
    "def getMask(img, RoiDefined=False):\n",
    "    \n",
    "    a, b = -1/4, 4\n",
    "    kernel = np.array([[a,a,a],[a,b,a],[a,a,a]])\n",
    "    img = cv.filter2D(img,-1,kernel)\n",
    "    img = cv.bitwise_not(img, img)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    limiar, img = cv.threshold(img, 30, 255, cv.THRESH_BINARY) # limiar de otsu inclui as sombras\n",
    "    \n",
    "    if(RoiDefined):\n",
    "        size = 7\n",
    "    else:\n",
    "        size = 31\n",
    "    \n",
    "    stt = cv.getStructuringElement(cv.MORPH_ELLIPSE, (size,size))\n",
    "    mask = cv.morphologyEx(img, cv.MORPH_CLOSE, stt, iterations=1)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def findMultiplesCoin(imgCol):\n",
    "    \n",
    "    imgBin = getMask(imgCol)\n",
    "    imgCol = cv.bitwise_and(imgCol, imgCol, mask=imgBin)\n",
    "    \n",
    "    img = cv.cvtColor(imgCol, cv.COLOR_BGR2GRAY)\n",
    "    img = cv.blur(img, (9,9))\n",
    "    \n",
    "#     showit(img, 1)\n",
    "    \n",
    "    circles = cv.HoughCircles(img,method=cv.HOUGH_GRADIENT,dp=1,minDist=100,\n",
    "                               param1=50,param2=50,minRadius=40,maxRadius=80)\n",
    "    \n",
    "    return circles\n",
    "\n",
    "# Imagem que será analisada\n",
    "img = cv.imread(\"datacoins/juntas/10front-10front-25front-5front-5back-10back-10front.jpg\")\n",
    "img = resize(img, 800)\n",
    "\n",
    "output = img.copy()\n",
    "\n",
    "circles = findMultiplesCoin(img)\n",
    "\n",
    "count = 0\n",
    "if circles is not None:\n",
    "    # coordinates and radii\n",
    "    circles = np.round(circles[0,:]).astype(int)\n",
    "    \n",
    "    for (x, y, d) in circles:\n",
    "        count += 1\n",
    "        d += 5\n",
    "                \n",
    "        roi = img[y-d:y+d, x-d:x+d]\n",
    "        \n",
    "        imgBinRoi = getMask(roi, True)\n",
    "        roi = cv.bitwise_and(roi, roi, mask=imgBinRoi)\n",
    "    \n",
    "        showit(roi, 1)\n",
    "        \n",
    "        coin, chance = predictCoin(roi)\n",
    "        \n",
    "        chance = str(int(chance*100)) + \" %\"\n",
    "        \n",
    "        cv.circle(output, (x,y), d, (0, 255, 0), 2)\n",
    "        cv.putText(output, coin, (x - 40, y), cv.FONT_HERSHEY_PLAIN,\n",
    "                   1.5, (0, 255, 0), thickness=2, lineType=cv.LINE_AA)\n",
    "        \n",
    "        cv.putText(output, chance, (x - 20, y+30), cv.FONT_HERSHEY_PLAIN,\n",
    "                   1.5, (0, 255, 0), thickness=2, lineType=cv.LINE_AA)\n",
    "\n",
    "showit(output, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     height,width,depth = im.shape\n",
    "# circle_img = np.zeros((height,width), np.uint8)\n",
    "# cv2.circle(circle_img,(width//2,height//2),height//2,255,thickness=-1)\n",
    "# masked_data = cv2.bitwise_and(im, im, mask=circle_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivo ARFF para testar no Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile as exist\n",
    "\n",
    "def gravar_arquivo_arff(base_teste, classes):\n",
    "    tam = len(base_teste[0])\n",
    "    file = open('data.arff','w') \n",
    " \n",
    "    file.write('@relation teste\\n') \n",
    "    for i in range(tam):\n",
    "        file.write('@attribute '+ str(i) +' NUMERIC\\n') \n",
    "    \n",
    "    file.write('@attribute classes {')\n",
    "    \n",
    "    a = set(classes)\n",
    "    \n",
    "    for i in a:\n",
    "        file.write(str(i)+',')\n",
    "    \n",
    "    file.write('}')    \n",
    "    for i in range(tam):\n",
    "         len(set(classes))\n",
    "    \n",
    "    file.write('\\n@data\\n') \n",
    "\n",
    "    for item in base_teste:\n",
    "        for i in range(len(item)):\n",
    "            file.write(\"%s,\" % str(item[0][i])) \n",
    "        file.write(\"%s\\n\" % item[1])    \n",
    " \n",
    "    file.close()\n",
    "    \n",
    "if(not exist(\"data.arff\")):\n",
    "    gravar_arquivo_arff(arffData,classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
